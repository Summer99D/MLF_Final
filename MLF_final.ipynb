{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "11F13qzwV0nmo5bYuBkRs-edIkyObGGhR",
      "authorship_tag": "ABX9TyNSskiOq3Rl3TFECfZdXQsi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Summer99D/MLF_Final/blob/main/MLF_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Kxws0VqPUfaI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from category_encoders import TargetEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDq0oJBPVz44",
        "outputId": "8287d2ba-566c-4792-dfcb-bcf0f2465b72"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_trns_df= pd.read_csv('/content/drive/MyDrive/MLF/test_transaction.csv')\n",
        "test_id_df= pd.read_csv('/content/drive/MyDrive/MLF/test_identity.csv')\n",
        "train_trns_df= pd.read_csv('/content/drive/MyDrive/MLF/train_transaction.csv')\n",
        "train_id_df= pd.read_csv('/content/drive/MyDrive/MLF/train_identity.csv')\n"
      ],
      "metadata": {
        "id": "VK3bLxK6UmtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_trns_df.describe)"
      ],
      "metadata": {
        "id": "WFR9HD5KWue4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_id_df.describe)"
      ],
      "metadata": {
        "id": "5Nt7PjijXJsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_id_df.describe)\n",
        "print(train_id_df.columns)"
      ],
      "metadata": {
        "id": "jEFA0_GAXSyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_trns_df.describe)\n",
        "print(train_trns_df.columns)"
      ],
      "metadata": {
        "id": "qiZfHMaFXXao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## I will be merging on \"transaction id\"\n",
        "train_merged= pd.merge(train_trns_df, train_id_df, on='TransactionID', how='left')\n",
        "test_merged= pd.merge(test_trns_df, test_id_df, on='TransactionID', how='left')"
      ],
      "metadata": {
        "id": "EdNeh9zwXb-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_merged.shape)## we have 434 variables\n",
        "print(test_merged.shape)"
      ],
      "metadata": {
        "id": "pxsID0SKaRCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inspecting NaNs"
      ],
      "metadata": {
        "id": "Xv7aIDlBZux2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training data"
      ],
      "metadata": {
        "id": "VKIMUAPHab5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Calculate NaN statistics\n",
        "nan_percentage_train = train_merged.isnull().mean() * 100\n",
        "nan_percentage_train = nan_percentage_train.sort_values(ascending=False)\n",
        "\n",
        "# Step 2: Summary statistics\n",
        "print(\"NaN Distribution Across Columns:\")\n",
        "print(f\"Total rows: {train_merged.shape[0]}\")\n",
        "print(f\"Total columns: {train_merged.shape[1]}\")\n",
        "print(f\"Columns with >30% missing values: {(nan_percentage_train > 30).sum()}\") ##removing columns with more than 30% missing vlaues\n",
        "print(\"\\nTop 10 columns with highest missing values:\")\n",
        "print(nan_percentage_train.head(10))\n"
      ],
      "metadata": {
        "id": "6R-1f7HXZyIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot 1: Bar plot of NaN percentages (top 50 columns)\n",
        "plt.figure(figsize=(15, 8))\n",
        "nan_percentage_train.head(50).plot(kind='bar')\n",
        "plt.title('NaN % Before Preprocessing (Top 50 Columns)')\n",
        "plt.xlabel('Column name')\n",
        "plt.ylabel('Missing Value %')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/drive/MyDrive/nan_bar_plot_before.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iRgK6Lhqcqta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(nan_percentage_train.describe)"
      ],
      "metadata": {
        "id": "hd6A-Sgxa6Kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove columns with >30% missing values\n",
        "columns_to_drop = nan_percentage_train[nan_percentage_train > 30].index\n",
        "print(f\"Removing {len(columns_to_drop)} columns with >30% missing values:\")\n",
        "print(columns_to_drop.tolist())\n",
        "train_data_cleaned = train_merged.drop(columns=columns_to_drop)"
      ],
      "metadata": {
        "id": "hICFRJvNcRwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## I wanna check data types\n",
        "train_data_cleaned.dtypes"
      ],
      "metadata": {
        "id": "qLIGkSdsfOPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute NaNs in all columns with the mean (for numeric columns only)\n",
        "train_data_cleaned = train_data_cleaned.fillna(train_data_cleaned.mean(numeric_only=True))"
      ],
      "metadata": {
        "id": "Gesh_r-EoHVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Identify column types\n",
        "num_cols = train_data_cleaned.select_dtypes(include=['float64', 'int64']).columns\n",
        "cat_cols = train_data_cleaned.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "num_imputer = SimpleImputer(strategy='mean')\n",
        "train_data_cleaned[num_cols] = num_imputer.fit_transform(train_data_cleaned[num_cols])\n",
        "\n",
        "\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "train_data_cleaned[cat_cols] = cat_imputer.fit_transform(train_data_cleaned[cat_cols])\n"
      ],
      "metadata": {
        "id": "2jK3X0VBx7Xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify no NaNs\n",
        "nan_percentage_cleaned = train_data_cleaned.isnull().mean() * 100\n",
        "print(\"\\nNaN percentages after imputation (should be 0%):\")\n",
        "print(nan_percentage_cleaned[nan_percentage_cleaned > 0])"
      ],
      "metadata": {
        "id": "foDN7ovX1jT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Data"
      ],
      "metadata": {
        "id": "OzsGhZbYkZVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Calculate NaN statistics\n",
        "nan_percentage_test = test_merged.isnull().mean() * 100\n",
        "nan_percentage_test = nan_percentage_test.sort_values(ascending=False)\n",
        "\n",
        "# Step 2: Summary statistics\n",
        "print(\"NaN Distribution Across Columns:\")\n",
        "print(f\"Total rows: {test_merged.shape[0]}\")\n",
        "print(f\"Total columns: {test_merged.shape[1]}\")\n",
        "print(f\"Columns with >30% missing values: {(nan_percentage_test > 30).sum()}\") ##removing columns with more than 30% missing vlaues\n",
        "print(\"\\nTop 10 columns with highest missing values:\")\n",
        "print(nan_percentage_test.head(10))"
      ],
      "metadata": {
        "id": "kk2c9qixkam_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar plot: Top 50 columns\n",
        "plt.figure(figsize=(15, 8))\n",
        "nan_percentage_test.head(50).plot(kind='bar')\n",
        "plt.title('NaN % Before Preprocessing (Top 50 Columns)')\n",
        "plt.xlabel('Column name')\n",
        "plt.ylabel('Missing Value %')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/drive/MyDrive/nan_bar_plot_before.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "it_S48IIksdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove columns with >30% missing values\n",
        "columns_to_drop_test = nan_percentage_test[nan_percentage_test > 30].index\n",
        "print(f\"Removing {len(columns_to_drop_test)} columns with >30% missing values:\")\n",
        "print(columns_to_drop_test.tolist())\n",
        "test_data_cleaned = test_merged.drop(columns=columns_to_drop_test)"
      ],
      "metadata": {
        "id": "JjcsB9tPk8dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute NaNs in all columns with the mean (for numeric columns only)\n",
        "test_data_cleaned = test_data_cleaned.fillna(test_data_cleaned.mean(numeric_only=True))"
      ],
      "metadata": {
        "id": "72EIjIEblLcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tm6FQWWQ1hK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running PCA"
      ],
      "metadata": {
        "id": "NZTY_JGloYgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Prepare for PCA\n",
        "X = train_data_cleaned.drop(columns=['isFraud', 'TransactionID'])\n",
        "y = train_data_cleaned['isFraud']\n"
      ],
      "metadata": {
        "id": "JxXUpDqF4zut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##encoding them!\n",
        "print(\"\\nCategorical Columns:\", cat_cols.tolist())\n"
      ],
      "metadata": {
        "id": "ufSYkGBn41sQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode non-numerical columns\n",
        "print(\"\\nApplying one-hot encoding to non-numerical columns\")\n",
        "print(f\"Non-numerical columns: {cat_cols.tolist()}\")\n",
        "X_encoded = pd.get_dummies(X, columns=cat_cols, drop_first=True, sparse=True)\n",
        "X_encoded = X_encoded.sparse.to_coo().tocsr()\n",
        "print(\"Encoded data shape:\", X_encoded.shape)\n",
        "print(\"Sample encoded columns:\", X_encoded.columns[:10].tolist())"
      ],
      "metadata": {
        "id": "5HLjczgP5imP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}